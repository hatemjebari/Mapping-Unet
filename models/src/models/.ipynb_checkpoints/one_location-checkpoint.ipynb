{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3629d6-92da-4c86-9cb6-6721673f234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/resifis/anaconda3/envs/kaustenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4 as nc\n",
    "from scipy import signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20a56c9-fc17-4b0b-81f1-0a448006e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = os.environ.get(\"DATAPATH\",\"/home/resifis/Desktop/kaustcode/Packages/processed_clean_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24826619-48b1-422f-a3eb-76be54e4fce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water_vapor\n",
      "pressure\n"
     ]
    }
   ],
   "source": [
    "class OneLoncationData():\n",
    "    def __init__(self,lat,lon):\n",
    "        self.lat = lat \n",
    "        self.lon = lon\n",
    "        self.netcdf_dataset_aod = Dataset(os.path.join(DATAPATH,\"aod.nc\") ,mode = 'r')\n",
    "        self.netcdf_dataset_cc_low = self.loat_clouds(\"low\")\n",
    "        self.netcdf_dataset_cc_med = self.loat_clouds(\"medium\")\n",
    "        self.netcdf_dataset_cc_high = self.loat_clouds(\"high\")\n",
    "        self.GHI = Dataset(os.path.join(DATAPATH,\"ghi.nc\") ,mode = 'r')\n",
    "        self.netcdf_dataset_wv = Dataset(os.path.join(DATAPATH,\"water_vapor_new.nc\"),model = 'r')\n",
    "        self.netcdf_dataset_ozone = Dataset(os.path.join(DATAPATH,\"ozone.nc\") ,mode = 'r')\n",
    "        self.netcdf_dataset_t2 = Dataset( os.path.join(DATAPATH,\"t2.nc\"),mode = 'r')\n",
    "        self.netcdf_dataset_td2 = Dataset(os.path.join(DATAPATH,\"dt2.nc\"),mode = 'r')\n",
    "        self.netcdf_dataset_mslp = Dataset(os.path.join(DATAPATH,\"mslp.nc\"),mode = 'r')\n",
    "        self.netcdf_dataset_rain = Dataset(os.path.join(DATAPATH,\"rain.nc\"),mode = 'r')\n",
    "        self.netcdf_dataset_WD = Dataset(os.path.join(DATAPATH,\"WD.nc\"),mode = 'r')\n",
    "        self.netcdf_dataset_WS = Dataset(os.path.join(DATAPATH,\"WS.nc\"),mode = 'r')\n",
    "        self.len_ = np.array(self.netcdf_dataset_cc_med.variables[\"cc\"][:,self.lat,self.lon]).shape[0]\n",
    "        \n",
    "    def loat_clouds(self,cloud_type):\n",
    "        if cloud_type == \"high\":\n",
    "            data_path = os.path.join(DATAPATH,\"hcloud.nc\")\n",
    "            netcdf_dataset_cc = Dataset(data_path,mode = 'r')\n",
    "        elif cloud_type == \"medium\":\n",
    "            data_path = os.path.join(DATAPATH,\"mcloud.nc\")\n",
    "            netcdf_dataset_cc = Dataset(data_path,mode = 'r')\n",
    "        else :\n",
    "            data_path = os.path.join(DATAPATH,\"lcloud.nc\")\n",
    "            netcdf_dataset_cc = Dataset(data_path,mode = 'r')\n",
    "        return netcdf_dataset_cc\n",
    "        \n",
    "    def load_(self):\n",
    "        aod = np.array(self.netcdf_dataset_aod.variables[\"aod5503d\"][:,self.lat,self.lon])\n",
    "        #Clouds\n",
    "        cloud_high = np.array(self.netcdf_dataset_cc_high.variables[\"cc\"][:,self.lat,self.lon])\n",
    "        cloud_low = np.array(self.netcdf_dataset_cc_low.variables[\"cc\"][:,self.lat,self.lon])\n",
    "        cloud_med = np.array(self.netcdf_dataset_cc_med.variables[\"cc\"][:,self.lat,self.lon])\n",
    "    \n",
    "        \n",
    "        #GHI\n",
    "        GHI_data = np.array(self.GHI.variables[\"ghi\"][:,self.lat,self.lon])\n",
    "        print(\"water_vapor\")\n",
    "        # Water Vapor\n",
    "        water_vapor = np.array(self.netcdf_dataset_wv.variables[\"qvapor\"][:,self.lat,self.lon])\n",
    "        #Ozone\n",
    "        ozone = np.array(self.netcdf_dataset_ozone.variables[\"o3rad\"][:,self.lat,self.lon])\n",
    "        \n",
    "        #T2\n",
    "        t2 = np.array(self.netcdf_dataset_t2.variables[\"t2\"][:,self.lat,self.lon])\n",
    "        \n",
    "        #TD2\n",
    "        td2 = np.array(self.netcdf_dataset_td2.variables[\"td2\"][:,self.lat,self.lon])\n",
    "        \n",
    "        #MSLP\n",
    "        print(\"pressure\")\n",
    "        mslp = np.array(self.netcdf_dataset_mslp.variables[\"mslp\"][:,self.lat,self.lon])\n",
    "    \n",
    "        # Rain \n",
    "        rain = np.array(self.netcdf_dataset_rain.variables[\"rain\"][:,self.lat,self.lon])\n",
    "    \n",
    "        # Wind Speeed\n",
    "        WD = np.array(self.netcdf_dataset_WD.variables[\"WD\"][:,self.lat,self.lon])\n",
    "        \n",
    "        # Wind Speed\n",
    "        WS = np.array(self.netcdf_dataset_WS.variables[\"WS\"][:,self.lat,self.lon])\n",
    "        \n",
    "        \n",
    "        #Create DataFrame\n",
    "        all_data = pd.DataFrame()\n",
    "        all_data['aod'] = aod\n",
    "        all_data['water_vapor'] = water_vapor\n",
    "        all_data['ozone'] = ozone\n",
    "        all_data['cloud_high'] = cloud_high\n",
    "        all_data['cloud_low'] = cloud_low\n",
    "        all_data['cloud_med'] = cloud_med\n",
    "        all_data['t2'] = t2\n",
    "        all_data['td2'] = td2\n",
    "        all_data['rain'] = rain\n",
    "        all_data['mslp'] = mslp\n",
    "        all_data['WS'] = WS\n",
    "        all_data['WD'] = WD\n",
    "        all_data['ghi'] = GHI_data\n",
    "        return all_data\n",
    "    \n",
    "lat = 120\n",
    "lon = 120\n",
    "OLD = OneLoncationData(lat,lon)\n",
    "data = OLD.load_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc038965-998d-4c5d-b324-337bb2dc95da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aod</th>\n",
       "      <th>water_vapor</th>\n",
       "      <th>ozone</th>\n",
       "      <th>cloud_high</th>\n",
       "      <th>cloud_low</th>\n",
       "      <th>cloud_med</th>\n",
       "      <th>t2</th>\n",
       "      <th>td2</th>\n",
       "      <th>rain</th>\n",
       "      <th>mslp</th>\n",
       "      <th>WS</th>\n",
       "      <th>WD</th>\n",
       "      <th>ghi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101301</td>\n",
       "      <td>0.025933</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.279999</td>\n",
       "      <td>286.600006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101790.281250</td>\n",
       "      <td>6.208583</td>\n",
       "      <td>265.572205</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101297</td>\n",
       "      <td>0.023875</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.200012</td>\n",
       "      <td>284.700012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101775.109375</td>\n",
       "      <td>8.286356</td>\n",
       "      <td>261.259827</td>\n",
       "      <td>64.441025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.101293</td>\n",
       "      <td>0.024174</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.200012</td>\n",
       "      <td>285.100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101800.296875</td>\n",
       "      <td>8.305449</td>\n",
       "      <td>260.441528</td>\n",
       "      <td>267.917175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101293</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.380005</td>\n",
       "      <td>284.299988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101836.890625</td>\n",
       "      <td>8.189384</td>\n",
       "      <td>257.021545</td>\n",
       "      <td>461.667755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101280</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.839996</td>\n",
       "      <td>284.600006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101833.593750</td>\n",
       "      <td>7.551007</td>\n",
       "      <td>260.169342</td>\n",
       "      <td>611.182678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        aod  water_vapor     ozone  cloud_high  cloud_low  cloud_med  \\\n",
       "0  0.101301     0.025933  0.000001         0.0        0.0        0.0   \n",
       "1  0.101297     0.023875  0.000001         0.0        0.0        0.0   \n",
       "2  0.101293     0.024174  0.000001         0.0        0.0        0.0   \n",
       "3  0.101293     0.023209  0.000001         0.0        0.0        0.0   \n",
       "4  0.101280     0.022606  0.000001         0.0        0.0        0.0   \n",
       "\n",
       "           t2         td2  rain           mslp        WS          WD  \\\n",
       "0  295.279999  286.600006   0.0  101790.281250  6.208583  265.572205   \n",
       "1  295.200012  284.700012   0.0  101775.109375  8.286356  261.259827   \n",
       "2  295.200012  285.100006   0.0  101800.296875  8.305449  260.441528   \n",
       "3  295.380005  284.299988   0.0  101836.890625  8.189384  257.021545   \n",
       "4  295.839996  284.600006   0.0  101833.593750  7.551007  260.169342   \n",
       "\n",
       "          ghi  \n",
       "0    0.000000  \n",
       "1   64.441025  \n",
       "2  267.917175  \n",
       "3  461.667755  \n",
       "4  611.182678  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff97870f-1e78-41c1-af42-b16dd3e099cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48222, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c8ed07b-0b62-4f3c-9025-4f074b9c829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:35000]\n",
    "valid = data.iloc[35000:45000]\n",
    "test = data.iloc[45000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b22186-2aca-49c7-bab2-06a589294bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "class Dataset():\n",
    "    def __init__(self,data):\n",
    "        self.data = data.copy()\n",
    "        self.target = self.data[['ghi']]\n",
    "        self.data.drop('ghi',axis = 1,inplace = True)\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaled = self.scaler.fit_transform(self.data.to_numpy())\n",
    "        self.scaled_data = pd.DataFrame(self.scaled, columns=['aod', 'water_vapor', 'ozone', 'cloud_high', 'cloud_low', 'cloud_med',\n",
    "       't2', 'td2', 'rain', 'mslp', 'WS', 'WD'])\n",
    "        self.scaled_data.dropna(inplace = True)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self,item):\n",
    "        out = dict()\n",
    "        out['data'] = torch.tensor(self.scaled_data.iloc[item].values,dtype = torch.float)\n",
    "        out['target'] = torch.tensor(self.target.iloc[item].values,dtype = torch.float)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cba6e2e-9c66-4732-85a6-ed271e8863e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = Dataset(train)\n",
    "ValidData = Dataset(valid)\n",
    "TestData = Dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0306e34b-71e1-43e8-ad86-ff62c3a5631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)  # cpu\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = True \n",
    "setup_seed(15)\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(NN,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = self.input_size,out_features = 10000)\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.block1 = nn.Sequential(self.fc1,\n",
    "                                    self.relu1,\n",
    "                                    self.dropout1,\n",
    "                                   )\n",
    "        \n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features = 10000,out_features = 5000)\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.block2 = nn.Sequential(self.fc2,\n",
    "                                    self.relu2,\n",
    "                                    self.dropout2,\n",
    "                                   )\n",
    "        \n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features = 5000,out_features = 2048)\n",
    "        self.relu3 = nn.ReLU(True)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.block3 = nn.Sequential(self.fc3,\n",
    "                                    self.relu3,\n",
    "                                    self.dropout3,\n",
    "                                   )\n",
    "        \n",
    "        \n",
    "        self.fc4 = nn.Linear(in_features = 2048,out_features = 1024)\n",
    "        self.relu4 = nn.ReLU(True)\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "        self.block4 = nn.Sequential(self.fc4,\n",
    "                                    self.relu4,\n",
    "                                    self.dropout4,\n",
    "                                   )\n",
    "        \n",
    "        self.fc5 = nn.Linear(in_features = 1024,out_features = 512)\n",
    "        self.relu5 = nn.ReLU(True)\n",
    "        self.dropout5 = nn.Dropout(0.3)\n",
    "        self.block5 = nn.Sequential(self.fc5,\n",
    "                                    self.relu5,\n",
    "                                    self.dropout5,\n",
    "                                   )\n",
    "        \n",
    "        self.fc6 = nn.Linear(in_features = 512,out_features = 256)\n",
    "        self.relu6 = nn.ReLU(True)\n",
    "        self.dropout6 = nn.Dropout(0.3)\n",
    "        self.block6 = nn.Sequential(self.fc6,\n",
    "                                    self.relu6,\n",
    "                                    self.dropout6,\n",
    "                                   )\n",
    "        \n",
    "        self.fc7 = nn.Linear(in_features = 256,out_features = 128)\n",
    "        self.relu7 = nn.ReLU(True)\n",
    "        self.dropout7 = nn.Dropout(0.3)\n",
    "        self.block7 = nn.Sequential(self.fc7,\n",
    "                                    self.relu7,\n",
    "                                    self.dropout7,\n",
    "                                   )\n",
    "        \n",
    "        self.fc8 = nn.Linear(in_features = 128,out_features = 1)\n",
    "        self.block8 = nn.Sequential(self.fc8)\n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "        x = self.block8(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46e81df9-5405-4a42-92a7-4c4e3ab9b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce8844d-68b7-4d41-b5ed-71523005f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m,nn.Conv3d):\n",
    "        torch.nn.init.normal_(m.weight)\n",
    "        #m.bias.data.fill_(0.01)\n",
    "    if isinstance(m,nn.ConvTranspose3d):\n",
    "        torch.nn.init.normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if isinstance(m,nn.BatchNorm3d):\n",
    "        torch.nn.init.normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.normal_(m.weight)\n",
    "        m.bias.data.fill_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "205135cf-c3bc-4fa7-9b7c-12d0e62b43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor = 0.2,\n",
    "                                                       patience = 3,\n",
    "                                                       verbose = True)\n",
    "\n",
    "shuffle_trainloader = False\n",
    "train_batch_size = 32\n",
    "shuffle_validloader = False\n",
    "valid_batch_size = 32\n",
    "epoch =50\n",
    "verbose = True\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04416b61-766b-4259-b580-2ccacbe79dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.apply(init_weights)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4036c74a-5c33-4623-852f-bc75c4a208df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import neptune.new as neptuneTrue\n",
    "from neptune.new.types import File\n",
    "import torch.nn.init as weight_init\n",
    "from torch.utils.data import RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MODELS_WEIGHTS = os.environ.get(\"MODELS_WEIGHTS\",\"/home/resifis/Desktop/kaustcode/Packages/models/src/model/\")\n",
    "\n",
    "NEPTUNE_API_TOKENS = os.environ.get(\"NEPTUNE_API_TOKENS\",\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMDkxNzQyNS1iZjk1LTRiYzQtYmY3OS1jMzBkZjA4ZDhkNTAifQ==\")\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Training():\n",
    "    def __init__(self,train_config):\n",
    "        self.train_config = train_config\n",
    "        \n",
    "    def _initialize_weights(self,net):\n",
    "        for name, param in net.named_parameters(): \n",
    "            weight_init.normal_(param)\n",
    "        \n",
    "    def train_fn(self,model,train_loader):\n",
    "        self.train_config.model.train()\n",
    "        \n",
    "        tr_loss = 0\n",
    "        counter = 0\n",
    "        losses = AverageMeter()\n",
    "        tqt = tqdm(enumerate(train_loader),total = len(train_loader))\n",
    "        for index,train_batch in tqt:\n",
    "            data = train_batch[\"data\"].to(self.train_config.device)\n",
    "            target = train_batch[\"target\"].to(self.train_config.device)\n",
    "            self.train_config.optimizer.zero_grad()\n",
    "            pred_target = model(data)\n",
    "            print(pred_target)\n",
    "            target = target.squeeze(1)\n",
    "            train_loss = self.train_config.criterion(pred_target,target)\n",
    "            train_loss.backward()\n",
    "            self.train_config.optimizer.step()\n",
    "            tr_loss += train_loss.item()        \n",
    "            counter = counter + 1\n",
    "            losses.update(train_loss.item(),pred_target.size(0))\n",
    "            tqt.set_postfix(Loss = losses.avg, batch_number = index)\n",
    "            return losses.avg\n",
    "\n",
    "    def valid_fn(self,model,validation_loader):\n",
    "        self.train_config.model.eval()\n",
    "        val_loss = 0\n",
    "        counter = 0\n",
    "        losses = AverageMeter()\n",
    "        tqt = tqdm(enumerate(validation_loader),total = len(validation_loader))\n",
    "        with torch.no_grad():\n",
    "            for index, valid_batch in tqt :\n",
    "                data = valid_batch[\"data\"].to(self.train_config.device)\n",
    "                target = valid_batch[\"target\"].to(self.train_config.device)\n",
    "                self.train_config.optimizer.zero_grad()\n",
    "                pred_target = model(data)\n",
    "                target = target.squeeze(1)\n",
    "                validation_loss = self.train_config.criterion(pred_target,target)\n",
    "                val_loss += validation_loss.item()        \n",
    "                counter = counter + 1\n",
    "                losses.update(validation_loss.item(),pred_target.size(0))\n",
    "                tqt.set_postfix(loss = losses.avg, batch_number = index)\n",
    "        return losses.avg\n",
    "    \n",
    "    \n",
    "    def get_dataloader(self,train_dataset,valid_dataset):\n",
    "        \n",
    "        train_sampler = RandomSampler(train_dataset,replacement = False,num_samples = 5000)\n",
    "        valid_sampler = RandomSampler(valid_dataset,replacement = False,num_samples = 1500)\n",
    "        \n",
    "        train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                        shuffle = self.train_config.shuffle_trainloader,\n",
    "                                                        batch_size = self.train_config.train_batch_size,\n",
    "                                                        sampler = train_sampler,\n",
    "                                                       )\n",
    "        valid_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                                        shuffle = self.train_config.shuffle_validloader,\n",
    "                                                        batch_size = self.train_config.valid_batch_size,\n",
    "                                                        sampler = valid_sampler,\n",
    "                                                       )\n",
    "        return train_data_loader,valid_data_loader\n",
    "    \n",
    "    @staticmethod\n",
    "    def checkpoints(epoch,model,optimizer,loss,exp):\n",
    "        path = os.path.join(MODELS_WEIGHTS,f\"weights-{exp}.pt\")\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, path)\n",
    "        \n",
    "    def fit(self,train_dataset,valid_dataset):\n",
    "        train_loss = []\n",
    "        valid_loss = []\n",
    "        best = 1e15\n",
    "        run = neptune.init(project=\"sofienresifi1997/KaustProject\",\n",
    "                           api_token=NEPTUNE_API_TOKENS,\n",
    "                          )\n",
    "\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.train_config.epoch):\n",
    "            train_data_loader,valid_data_loader = self.get_dataloader(train_dataset,valid_dataset)\n",
    "            if self.train_config.verbose :\n",
    "                print(f\".........EPOCH {epoch}........\")\n",
    "            tr_loss = self.train_fn(self.train_config.model,train_data_loader)\n",
    "            train_loss.append(tr_loss)\n",
    "            run[\"Train/loss\"].log(tr_loss)\n",
    "            if self.train_config.verbose :\n",
    "                print(f\".........Train Loss = {tr_loss}........\")\n",
    "            val_loss = self.valid_fn(self.train_config.model,valid_data_loader)\n",
    "            valid_loss.append(val_loss)\n",
    "            run[\"valid/loss\"].log(val_loss)\n",
    "            #Training.checkpoints(epoch,self.train_config.model,self.train_config.optimizer,val_loss,self.train_config.exp)\n",
    "            self.train_config.scheduler.step(val_loss)\n",
    "            if self.train_config.verbose:\n",
    "                print(f\"...........Validation Loss = {val_loss}.......\")\n",
    "\n",
    "            if val_loss < best :\n",
    "                best = val_loss\n",
    "                patience = 0\n",
    "            else:\n",
    "                print(\"Score is not improving with patient = \",patience)\n",
    "                patience +=1\n",
    "\n",
    "            if patience >= self.train_config.epoch:\n",
    "                print(f\"Early Stopping on Epoch {epoch}\")\n",
    "                print(f\"Best Loss = {best}\")\n",
    "                break\n",
    "                \n",
    "        \n",
    "        PATH = \"model_300.pth\"\n",
    "        torch.save(self.train_config.model.state_dict(),PATH)\n",
    "        self.train_config.model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2a3ce12-524e-44a1-8d83-e45dd0fd83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils.configtrain import *\n",
    "exp = 1\n",
    "train_config = TrainingConfig(model,\n",
    "                              criterion,\n",
    "                              optimizer,\n",
    "                              scheduler,\n",
    "                              device,\n",
    "                              shuffle_trainloader,\n",
    "                              train_batch_size,\n",
    "                              shuffle_validloader,\n",
    "                              valid_batch_size,\n",
    "                              epoch,\n",
    "                              verbose,\n",
    "                              exp\n",
    "                             )\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffcc6a14-bf81-421a-bf99-b285cf97e1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "https://app.neptune.ai/sofienresifi1997/KaustProject/e/KAUS-143\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      ".........EPOCH 0........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/157 [00:00<?, ?it/s, Loss=1.29e+10, batch_number=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9702e+10],\n",
      "        [-3.7754e+09],\n",
      "        [ 1.5598e+08],\n",
      "        [-1.1876e+10],\n",
      "        [ 1.8499e+10],\n",
      "        [ 1.6922e+10],\n",
      "        [ 2.5344e+10],\n",
      "        [ 1.0502e+10],\n",
      "        [-1.4628e+10],\n",
      "        [ 1.4471e+10],\n",
      "        [ 2.6989e+08],\n",
      "        [ 5.5069e+08],\n",
      "        [-1.8327e+10],\n",
      "        [ 9.5765e+09],\n",
      "        [-4.8519e+09],\n",
      "        [-1.4711e+10],\n",
      "        [-1.2706e+10],\n",
      "        [ 1.5476e+10],\n",
      "        [-1.6617e+10],\n",
      "        [-1.8939e+10],\n",
      "        [-1.3846e+10],\n",
      "        [-2.2592e+10],\n",
      "        [-4.3306e+09],\n",
      "        [ 8.4944e+09],\n",
      "        [-2.2004e+10],\n",
      "        [ 6.0620e+09],\n",
      "        [-3.3509e+10],\n",
      "        [ 1.4680e+10],\n",
      "        [ 9.3568e+07],\n",
      "        [-8.7816e+09],\n",
      "        [ 1.2844e+10],\n",
      "        [-1.8008e+10]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      ".........Train Loss = 12910822400.0........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<00:00, 142.62it/s, batch_number=46, loss=3.24e+9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........Validation Loss = 3237313906.0053334.......\n",
      ".........EPOCH 1........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/157 [00:00<?, ?it/s, Loss=2.08e+10, batch_number=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2240e+08],\n",
      "        [-4.4983e+10],\n",
      "        [-1.4466e+10],\n",
      "        [ 5.0882e+09],\n",
      "        [-2.6061e+10],\n",
      "        [-7.7833e+09],\n",
      "        [-2.6517e+10],\n",
      "        [ 1.0524e+10],\n",
      "        [-1.8665e+10],\n",
      "        [-1.3933e+10],\n",
      "        [-1.0121e+10],\n",
      "        [-1.3739e+10],\n",
      "        [-7.5471e+09],\n",
      "        [ 4.1123e+10],\n",
      "        [-2.9131e+10],\n",
      "        [-5.5102e+08],\n",
      "        [-3.5301e+10],\n",
      "        [-4.5688e+10],\n",
      "        [-3.5924e+10],\n",
      "        [ 6.3648e+09],\n",
      "        [-5.8757e+10],\n",
      "        [-2.2269e+10],\n",
      "        [-3.2881e+10],\n",
      "        [-3.6645e+10],\n",
      "        [ 1.5252e+10],\n",
      "        [ 1.6580e+10],\n",
      "        [-9.5476e+09],\n",
      "        [ 9.3284e+09],\n",
      "        [-1.3689e+10],\n",
      "        [-2.7711e+10],\n",
      "        [ 1.9279e+10],\n",
      "        [ 1.0023e+10]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      ".........Train Loss = 20802936832.0........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<00:00, 129.82it/s, batch_number=46, loss=3.27e+9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........Validation Loss = 3270161560.234667.......\n",
      "Score is not improving with patient =  0\n",
      ".........EPOCH 2........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/157 [00:00<?, ?it/s, Loss=1.43e+10, batch_number=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7848e+09],\n",
      "        [ 2.2410e+10],\n",
      "        [-1.7786e+10],\n",
      "        [-1.4798e+10],\n",
      "        [-1.3753e+10],\n",
      "        [-5.3632e+10],\n",
      "        [-1.3632e+10],\n",
      "        [-1.1486e+10],\n",
      "        [-2.0707e+10],\n",
      "        [ 5.8131e+09],\n",
      "        [ 1.1138e+10],\n",
      "        [-6.4065e+09],\n",
      "        [-2.1378e+10],\n",
      "        [-1.3624e+10],\n",
      "        [-1.4682e+10],\n",
      "        [-8.8022e+09],\n",
      "        [ 3.2902e+09],\n",
      "        [-6.9679e+09],\n",
      "        [-9.1841e+09],\n",
      "        [-1.3940e+10],\n",
      "        [ 5.4295e+09],\n",
      "        [ 3.6430e+09],\n",
      "        [-1.7075e+10],\n",
      "        [-2.5387e+10],\n",
      "        [ 1.9866e+10],\n",
      "        [ 1.0779e+10],\n",
      "        [-2.2279e+10],\n",
      "        [-7.3514e+09],\n",
      "        [-9.0236e+08],\n",
      "        [ 2.8057e+10],\n",
      "        [ 4.6735e+09],\n",
      "        [-2.7982e+10]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      ".........Train Loss = 14332403712.0........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<00:00, 182.57it/s, batch_number=46, loss=3.23e+9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........Validation Loss = 3233347081.5573335.......\n",
      ".........EPOCH 3........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/157 [00:00<?, ?it/s, Loss=1.61e+10, batch_number=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6321e+09],\n",
      "        [ 5.6091e+08],\n",
      "        [-3.9192e+09],\n",
      "        [ 8.1606e+09],\n",
      "        [-1.8136e+10],\n",
      "        [-2.6390e+10],\n",
      "        [ 4.6994e+10],\n",
      "        [-5.6788e+09],\n",
      "        [-5.8102e+09],\n",
      "        [ 4.2160e+09],\n",
      "        [ 4.9087e+09],\n",
      "        [-2.2394e+09],\n",
      "        [-3.4463e+10],\n",
      "        [-5.2394e+09],\n",
      "        [ 1.5294e+10],\n",
      "        [-4.9693e+09],\n",
      "        [-3.9013e+10],\n",
      "        [-2.7968e+10],\n",
      "        [-3.6145e+10],\n",
      "        [ 1.1314e+10],\n",
      "        [-2.3525e+08],\n",
      "        [ 2.1672e+10],\n",
      "        [ 1.0011e+10],\n",
      "        [-4.4624e+10],\n",
      "        [-1.4952e+10],\n",
      "        [-2.6946e+10],\n",
      "        [-5.1005e+08],\n",
      "        [ 1.5692e+10],\n",
      "        [-9.9916e+09],\n",
      "        [-2.7533e+10],\n",
      "        [ 2.4027e+10],\n",
      "        [-1.5826e+10]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      ".........Train Loss = 16096024576.0........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<00:00, 160.84it/s, batch_number=46, loss=3.23e+9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........Validation Loss = 3228402967.8933334.......\n",
      ".........EPOCH 4........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/157 [00:00<?, ?it/s, Loss=1.63e+10, batch_number=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1647e+10],\n",
      "        [-1.8380e+10],\n",
      "        [-3.4584e+10],\n",
      "        [-1.5904e+10],\n",
      "        [-1.2172e+10],\n",
      "        [ 1.8164e+10],\n",
      "        [ 1.4799e+10],\n",
      "        [ 5.1367e+09],\n",
      "        [-9.7602e+09],\n",
      "        [ 1.8167e+10],\n",
      "        [-5.0128e+09],\n",
      "        [ 7.5714e+09],\n",
      "        [-1.4045e+10],\n",
      "        [-9.9875e+09],\n",
      "        [ 9.7280e+09],\n",
      "        [-1.3558e+10],\n",
      "        [-2.0019e+10],\n",
      "        [ 1.9878e+10],\n",
      "        [-4.5497e+09],\n",
      "        [-4.4915e+09],\n",
      "        [ 2.5936e+10],\n",
      "        [-4.9295e+10],\n",
      "        [ 1.5831e+10],\n",
      "        [-3.5635e+10],\n",
      "        [ 1.1905e+10],\n",
      "        [ 2.2088e+10],\n",
      "        [-1.7745e+10],\n",
      "        [ 2.7446e+10],\n",
      "        [-3.3195e+09],\n",
      "        [-2.3841e+10],\n",
      "        [-8.9840e+09],\n",
      "        [-1.0964e+10]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      ".........Train Loss = 16266993664.0........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<00:00, 177.93it/s, batch_number=46, loss=3.27e+9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........Validation Loss = 3269654478.1653333.......\n",
      "Score is not improving with patient =  0\n",
      ".........EPOCH 5........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/157 [00:00<?, ?it/s, Loss=1.61e+10, batch_number=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9064e+10],\n",
      "        [ 1.2923e+10],\n",
      "        [-9.1324e+09],\n",
      "        [-1.1399e+10],\n",
      "        [-5.2098e+09],\n",
      "        [ 2.7427e+10],\n",
      "        [-3.7751e+09],\n",
      "        [-1.6935e+10],\n",
      "        [-7.1456e+09],\n",
      "        [-1.4775e+10],\n",
      "        [-1.2523e+10],\n",
      "        [ 3.1049e+10],\n",
      "        [-2.3844e+10],\n",
      "        [-2.6510e+09],\n",
      "        [-2.7342e+10],\n",
      "        [-2.3000e+10],\n",
      "        [ 1.9733e+10],\n",
      "        [-2.8859e+10],\n",
      "        [-4.2609e+09],\n",
      "        [ 5.0704e+09],\n",
      "        [-2.0674e+09],\n",
      "        [ 4.5815e+10],\n",
      "        [ 1.9607e+10],\n",
      "        [ 2.3621e+10],\n",
      "        [ 2.8790e+10],\n",
      "        [-2.0388e+10],\n",
      "        [-8.1655e+09],\n",
      "        [ 2.0891e+10],\n",
      "        [-5.2201e+09],\n",
      "        [-1.5560e+10],\n",
      "        [-2.7288e+09],\n",
      "        [ 1.7688e+10]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      ".........Train Loss = 16145612800.0........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<00:00, 148.97it/s, batch_number=46, loss=3.24e+9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........Validation Loss = 3244376371.2.......\n",
      "Score is not improving with patient =  1\n",
      ".........EPOCH 6........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                       | 0/157 [00:00<?, ?it/s, Loss=1.63e+10, batch_number=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9114e+10],\n",
      "        [-1.3632e+10],\n",
      "        [ 9.2542e+09],\n",
      "        [ 2.8950e+09],\n",
      "        [-1.9554e+10],\n",
      "        [-4.2237e+10],\n",
      "        [ 5.4626e+09],\n",
      "        [-4.6534e+10],\n",
      "        [-7.5264e+09],\n",
      "        [ 1.9636e+10],\n",
      "        [-5.3312e+10],\n",
      "        [-3.7923e+10],\n",
      "        [ 1.2343e+09],\n",
      "        [ 1.3485e+09],\n",
      "        [-7.4447e+09],\n",
      "        [-2.8614e+10],\n",
      "        [-2.4114e+10],\n",
      "        [-1.3274e+10],\n",
      "        [-2.4169e+10],\n",
      "        [ 4.2666e+09],\n",
      "        [ 2.3894e+10],\n",
      "        [ 3.6475e+08],\n",
      "        [ 9.6412e+09],\n",
      "        [ 1.0728e+10],\n",
      "        [-4.0632e+10],\n",
      "        [-3.8429e+09],\n",
      "        [ 3.8653e+09],\n",
      "        [-3.4194e+09],\n",
      "        [ 1.1857e+10],\n",
      "        [ 6.6832e+09],\n",
      "        [-1.3698e+10],\n",
      "        [-1.2917e+10]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      ".........Train Loss = 16346493952.0........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 31/47 [00:00<00:00, 146.88it/s, batch_number=30, loss=3.28e+9]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Training\")\n",
    "import neptune.new as neptune\n",
    "job = Training(train_config)\n",
    "job.fit(TrainData,ValidData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd65fbd-4a2f-41d1-b146-a059a52c02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(TestData):\n",
    "    test_loader = torch.utils.data.DataLoader(TestData,\n",
    "                                                    shuffle = False,\n",
    "                                                    batch_size = 32,\n",
    "                                                   )\n",
    "    model.eval()\n",
    "    tqt = tqdm(enumerate(test_loader),total = len(test_loader))\n",
    "    list_true =[]\n",
    "    list_pred = []\n",
    "    with torch.no_grad():\n",
    "        for index, test_batch in tqt :\n",
    "            data = test_batch[\"data\"].to(device)\n",
    "            target = test_batch[\"target\"].to(device)\n",
    "            pred_target = model(data)\n",
    "            target = target.squeeze(1)\n",
    "            list_pred.append(pred_target.detach().cpu())\n",
    "            list_true.append(target.detach().cpu())      \n",
    "    return list_true,list_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21f676-a9f8-49ea-ad1e-7d763118f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_true,list_pred = predict(TestData)\n",
    "res_true = torch.cat(list_true,dim = 0)\n",
    "res_pred = torch.cat(list_pred,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8258244-f0aa-4f8f-ab01-e513286d9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res_true[:100])\n",
    "plt.plot(res_pred[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a2968-200a-45c8-a22e-117001cb2bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
